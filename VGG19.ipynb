{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pwtTDYdd9hUO"
      ],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/matteo-bertini/Facial-Expression-Recognition)\n",
        "[![Open filled In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matteo-bertini/Facial-Expression-Recognition/blob/main/ResNet152V2.ipynb)\n",
        "\n",
        "# Importing the libraries\n",
        "The libraries to implement Five-Layers-CNN and related utilities are imported here."
      ],
      "metadata": {
        "id": "QKKuBv4kQVNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxv5Kt43IEWW",
        "outputId": "1f7e9af2-13d2-405a-87ab-633c498cccee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications import VGG19 \n",
        "import keras_tuner as kt\n",
        "from tensorflow import keras,convert_to_tensor\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T15:42:48.749154Z",
          "iopub.execute_input": "2022-12-19T15:42:48.75192Z",
          "iopub.status.idle": "2022-12-19T15:42:56.0274Z",
          "shell.execute_reply.started": "2022-12-19T15:42:48.751884Z",
          "shell.execute_reply": "2022-12-19T15:42:56.026244Z"
        },
        "trusted": true,
        "id": "VzZWnGZfQVNc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Check\n",
        "This section checks whether the GPU is in use or not."
      ],
      "metadata": {
        "id": "TylfoKwOZI4d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHWruOLHycQv"
      },
      "source": [
        "# Utilities\n",
        "Here we declare some functions that will be useful later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YN0JOk11144C"
      },
      "outputs": [],
      "source": [
        "# Returns a batch with n samples from the set passed in input\n",
        "def random_images(X,y,n):\n",
        "  X_len = X.shape[0]\n",
        "  ran_indices = random.sample(range(0,X_len,1),n)\n",
        "  to_ret_X = []\n",
        "  to_ret_y = []\n",
        "  for i in range(0,n):\n",
        "    to_ret_X.append(X[ran_indices[i]])\n",
        "    to_ret_y.append(y[ran_indices[i]])\n",
        "\n",
        "  return tf.stack(to_ret_X),tf.stack(to_ret_y)\n",
        "\n",
        "# Plots the images and their labels passed in input \n",
        "def print_images_with_labels(X,y):\n",
        "  emotions = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"]\n",
        "  num_images = X.shape[0]\n",
        "  fig = plt.figure(figsize = (2*num_images,2*num_images))\n",
        "  for i in range(0,num_images):\n",
        "    fig.add_subplot(1,num_images,i+1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(X[i].numpy().reshape(48,48),cmap=\"gray\")\n",
        "    plt.title(emotions[y[i].numpy().argmax()])\n",
        "  plt.show(fig)\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_gpu_available = len(tf.config.list_physical_devices('GPU'))\n",
        "if num_gpu_available == 0 :\n",
        "  print(\"You are not using GPU.\\n\")\n",
        "else:\n",
        "  print(\"You are using GPU.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8ePbkbWojHs",
        "outputId": "2b9a129e-f654-4044-87d2-4f837d7dcadc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are not using GPU.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Command to run to see the specs of the assigned GPU. (only valid if GPU is in use)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQo4jv1QssA5",
        "outputId": "6744f90a-1718-4a6b-911a-c101c20bde32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive"
      ],
      "metadata": {
        "id": "92iA1-hPQml9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRp8ClaxQqBL",
        "outputId": "e3af1459-457b-4367-de2c-b7a8090a1d11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset\n",
        "The dataset provided by the .csv file is uploaded and processed here.\n"
      ],
      "metadata": {
        "id": "iI-74bMbacrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset from the csv file\n",
        "In this section the file \"icml_face_data.csv\" is loaded inside a dataframe, which is processed and then divided into three other dataframes (one for train, one for validation and one for test) according to the value of the \"usage\" column."
      ],
      "metadata": {
        "id": "1UTFfsJbLhOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading icml_face_data.csv into dataframe df_icml\n",
        "df_icml = pd.read_csv(\"/content/drive/MyDrive/Facial-Expression-Recognition/challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv\",sep=\",\")\n",
        "\n",
        "# Columns renamed for easier access.\n",
        "df_icml.rename(columns = {' Usage':'usage'}, inplace = True)\n",
        "df_icml.rename(columns = {' pixels':'pixels'}, inplace = True)\n",
        "\n",
        "# Transforming pixel strings into 48x48x1 numpy arrays of float32\n",
        "df_icml[\"pixels\"] = df_icml['pixels'].apply(lambda x: np.array(x.split()).reshape(48, 48,1).astype('float32'))\n",
        "# Transforming 48x48x1 numpy arrays into 48x48x3 by coping the first channel\n",
        "df_icml[\"pixels\"] = df_icml[\"pixels\"].apply(lambda x : np.repeat(a=x,repeats=3,axis = 2))\n",
        "\n",
        "# Creating the X numpyarray\n",
        "X = df_icml[\"pixels\"]\n",
        "X = np.stack(X, axis=0)\n",
        "X=X/255.0\n",
        "print(\"X has shape: \")\n",
        "print(X.shape)\n",
        "\n",
        "# Creating the y numpyarray\n",
        "y = df_icml[\"emotion\"].to_numpy()\n",
        "y = to_categorical(y)\n",
        "print(\"y has shape: \")\n",
        "print(y.shape)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Data Augmentation phase \n",
        "\n",
        "# Declaration of the ImageDataGenerator with the transformations to apply to generate new images\n",
        "data_gen = ImageDataGenerator(rotation_range = 15,width_shift_range = 0.15,height_shift_range = 0.15,shear_range = 0.15,zoom_range = 0.15,horizontal_flip = True)\n",
        "\n",
        "# Disgust Class \n",
        "\n",
        "# Creating the X numpyarray with samples from disgust class\n",
        "X_disg = df_icml.loc[df_icml['emotion'].isin([1])][\"pixels\"]\n",
        "X_disg = np.stack(X_disg, axis=0)\n",
        "print(\"X_disg has shape: \")\n",
        "print(X_disg.shape)\n",
        "\n",
        "# Creating the y numpyarray with samples from disgust class\n",
        "y_disg = np.zeros((547,7))\n",
        "for i in range (0,y_disg.shape[0]):\n",
        "  y_disg[i][1] = 1 \n",
        "print(\"y_disg has shape: \")\n",
        "print(y_disg.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Adding the newly created images and labels to the original dataset\n",
        "i = 0\n",
        "while i < 9:\n",
        "  data_gen.fit(X_disg)\n",
        "  it = data_gen.flow(X_disg,y_disg,batch_size = 547,shuffle = True)\n",
        "  X_to_add = it.next()[0]\n",
        "  y_to_add = it.next()[1]\n",
        "  X = np.concatenate((X,X_to_add),axis = 0)\n",
        "  y = np.concatenate((y,y_to_add),axis = 0)\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "# Surprise Class \n",
        "\n",
        "# Creating the X numpyarray with samples from surprise class\n",
        "X_surp = df_icml.loc[df_icml['emotion'].isin([5])][\"pixels\"]\n",
        "X_surp = np.stack(X_surp, axis=0)\n",
        "print(\"X_surp has shape: \")\n",
        "print(X_surp.shape)\n",
        "\n",
        "# Creating the y numpyarray with samples from surprise class\n",
        "y_surp = np.zeros((4002,7))\n",
        "for i in range (0,y_surp.shape[0]):\n",
        "  y_surp[i][5] = 1 \n",
        "print(\"y_surp has shape: \")\n",
        "print(y_surp.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Adding the newly created images and labels to the original dataset\n",
        "i = 0\n",
        "while i < 9:\n",
        "  data_gen.fit(X_surp)\n",
        "  it = data_gen.flow(X_surp,y_surp,batch_size = 200,shuffle = True)\n",
        "  X_to_add = it.next()[0]\n",
        "  y_to_add = it.next()[1]\n",
        "  X = np.concatenate((X,X_to_add),axis = 0)\n",
        "  y = np.concatenate((y,y_to_add),axis = 0)\n",
        "  i=i+1\n",
        "\n",
        "print(X.shape,y.shape)\n",
        "\n",
        "# Creating the train,val,test split using sklearn library \n",
        "# ( the stratify option retains the same proportion of classes in the train and test\n",
        "#  sets that are found in the entire original dataset,it helps in the building of balanced train-test splits)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=True,stratify=y,random_state = 42)\n",
        "X_test,X_val,y_test,y_val = train_test_split(X_test,y_test,test_size=0.5,shuffle=True,stratify=y_test,random_state=42)\n",
        "\n",
        "# Transforming sets from numpy array to tensors\n",
        "X_train = convert_to_tensor(X_train)\n",
        "X_val = convert_to_tensor(X_val)\n",
        "X_test = convert_to_tensor(X_test)\n",
        "print(\"Sets shapes:\")\n",
        "print(\"X_train has shape: \")\n",
        "print(X_train.shape)\n",
        "print(\"y_train has shape: \")\n",
        "print(y_train.shape)\n",
        "print(\"X_val has shape: \")\n",
        "print(X_val.shape)\n",
        "print(\"y_val has shape: \")\n",
        "print(y_val.shape)\n",
        "print(\"X_test has shape: \")\n",
        "print(X_test.shape)\n",
        "print(\"y_test has shape: \")\n",
        "print(y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "x5oHyCP2Lg4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5a109f-ed11-4f3a-d9e8-2d97dd506a01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X has shape: \n",
            "(35887, 48, 48, 3)\n",
            "y has shape: \n",
            "(35887, 7)\n",
            "\n",
            "\n",
            "X_disg has shape: \n",
            "(547, 48, 48, 3)\n",
            "y_disg has shape: \n",
            "(547, 7)\n",
            "\n",
            "\n",
            "X_surp has shape: \n",
            "(4002, 48, 48, 3)\n",
            "y_surp has shape: \n",
            "(4002, 7)\n",
            "\n",
            "\n",
            "(42610, 48, 48, 3) (42610, 7)\n",
            "Sets shapes:\n",
            "X_train has shape: \n",
            "(34088, 48, 48, 3)\n",
            "y_train has shape: \n",
            "(34088, 7)\n",
            "X_val has shape: \n",
            "(4261, 48, 48, 3)\n",
            "y_val has shape: \n",
            "(4261, 7)\n",
            "X_test has shape: \n",
            "(4261, 48, 48, 3)\n",
            "y_test has shape: \n",
            "(4261, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment of class weights\n",
        "In this section, class weights are calculated and assigned. These weights are useful in the training phase to manage the imbalance between classes that emerged in the Exploratory Data Analysis.\n",
        "The following formula will be used to calculate the class weights:\\\n",
        "          **wj = n_samples / (n_classes * n_samplesj)**\\\n",
        "where:\n",
        "\n",
        "\n",
        "*   wj is the weight for each class (j is the index of the class)\n",
        "*   n_samples is the total number of samples or rows in the dataset\n",
        "*   n_classes is the total number of unique classes in the dataset\n",
        "*   n_samplesj is the total number of rows of the respective class (j is the index of the class)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eWM3pff49fYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the total number of samples in the train set\n",
        "n_samples = y_train.shape[0]\n",
        "\n",
        "# declaration of the weights dictionary to pass in the training phase\n",
        "weights = {0:0.0,1:0.0,2:0.0,3:0.0,4:0.0,5:0.0,6:0.0}\n",
        "\n",
        "# counting n_samples j for each class\n",
        "for j in range(n_samples):\n",
        "  idx = y_train[j].argmax()\n",
        "  weights[idx]=weights[idx]+1\n",
        "\n",
        "print(weights)\n",
        "# computing the weights for each class\n",
        "for j in range(7):\n",
        "  weights[j] = n_samples/ (7* weights[j])\n",
        "\n",
        "# visualizing the weights\n",
        "display(weights)"
      ],
      "metadata": {
        "id": "Sc0GYxmf-INj",
        "outputId": "ec588034-4fea-43de-d4ac-2a77e32add5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 3962.0, 1: 4376.0, 2: 4097.0, 3: 7191.0, 4: 4862.0, 5: 4642.0, 6: 4958.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{0: 1.2291050695896732,\n",
              " 1: 1.1128231914337947,\n",
              " 2: 1.1886049025419296,\n",
              " 3: 0.6771957009754256,\n",
              " 4: 1.001586648645472,\n",
              " 5: 1.049055210192651,\n",
              " 6: 0.9821932807007434}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the network structure\n",
        "Here the architecture of ResNet152V2 is imported from the library.\n"
      ],
      "metadata": {
        "id": "AK8uj6Mpah_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG19(include_top = True,weights=None,input_shape=(48,48,3),pooling=\"max\",classes=7)\n",
        "model._name = \"VGG19\"\n",
        "\n",
        "# After creating the structure of the network, we visualize it in a compact way.\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1jSXz49k3jbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c179ef-2bca-4f27-b723-966fc126ac95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"VGG19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              2101248   \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 7)                 28679     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,935,623\n",
            "Trainable params: 38,935,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compiling the model\n",
        "In this section the model is compiled, in particular are defined:\n",
        "\n",
        "\n",
        "*   the loss function (categorical crossentropy)\n",
        "*   the optimizator (adam optimizer)\n",
        "*   the evaluation metrics (accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nf9Vn1eGb-aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the loss function,the optimizer and the evaluation metrics\n",
        "opt = keras.optimizers.Adam()\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = opt,\n",
        "    metrics = ['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T15:43:41.423131Z",
          "iopub.execute_input": "2022-12-19T15:43:41.424081Z",
          "iopub.status.idle": "2022-12-19T15:43:41.439346Z",
          "shell.execute_reply.started": "2022-12-19T15:43:41.424044Z",
          "shell.execute_reply": "2022-12-19T15:43:41.438491Z"
        },
        "trusted": true,
        "id": "Wnih-C3rQVN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=11,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.2,\n",
        "    patience=1,\n",
        "    min_lr=0.0001,\n",
        "    verbose=1,\n",
        "    \n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T15:43:41.440534Z",
          "iopub.execute_input": "2022-12-19T15:43:41.441339Z",
          "iopub.status.idle": "2022-12-19T15:43:41.448614Z",
          "shell.execute_reply.started": "2022-12-19T15:43:41.441303Z",
          "shell.execute_reply": "2022-12-19T15:43:41.447676Z"
        },
        "trusted": true,
        "id": "1D4PikmQQVN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the VGG19\n",
        "in this section the net is trained on the training set."
      ],
      "metadata": {
        "id": "P1di7pz0eFPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the net\n",
        "\n",
        "print(\"Training:\\n\")\n",
        "history = model.fit(X_train,y_train,batch_size=32,epochs=15,callbacks=callbacks,validation_data=(X_val, y_val))\n",
        "\n",
        "# Saving the history to visualize the learning curves even without having trained the network (future use)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Facial-Expression-Recognition/Five_Layers_CNN_history.pi\", 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)\n"
      ],
      "metadata": {
        "id": "SYc2LycpEoKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning curves visualization\n",
        "Here the learning curves are displayed.\n",
        "In particular, it is displayed how the loss and accuracy change for the training set and for the validation set during the various training epochs."
      ],
      "metadata": {
        "id": "pwtTDYdd9hUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading training history from saved file\n",
        "with open(\"/content/drive/MyDrive/Facial-Expression-Recognition/Five_Layers_CNN_history.pi\", \"rb\") as file_pi:\n",
        "    history = pickle.load(file_pi)"
      ],
      "metadata": {
        "id": "23F88DKAPJGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAVKFSYoxgI8"
      },
      "outputs": [],
      "source": [
        "# visualizing the accuracy learning curve\n",
        "\n",
        "# creating the figure\n",
        "acc_lc = plt.figure(figsize = (10,10))\n",
        "\n",
        "# plotting training and validation accuracy\n",
        "plt.plot(history[\"accuracy\"])                                                         \n",
        "plt.plot(history['val_accuracy'])  \n",
        "\n",
        "# setting plot title\n",
        "plt.title('Model accuracy')\n",
        "\n",
        "# setting x and y ticks and labels for the plot\n",
        "plt.ylabel('Accuracy')\n",
        "#plt.yticks([0.0,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,1.0])\n",
        "plt.xlabel('Epoch')\n",
        "#plt.xticks(range(0,num_epochs+1))\n",
        "\n",
        "# setting the legend for the plot\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "\n",
        "# adding the grid\n",
        "plt.grid()\n",
        "\n",
        "# showing the figure\n",
        "plt.show(acc_lc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XidygRtJEdMU"
      },
      "outputs": [],
      "source": [
        "# visualizing the loss learning curves\n",
        "\n",
        "# creating the figure\n",
        "loss_lc = plt.figure(figsize = (10,10))\n",
        "\n",
        "# plotting training and validation accuracy\n",
        "plt.plot(history['loss'])                                                         \n",
        "plt.plot(history['val_loss'])  \n",
        "\n",
        "# setting plot title\n",
        "plt.title('Model loss')\n",
        "\n",
        "# setting x and y ticks and labels for the plot\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "#plt.xticks(range(0,num_epochs+1))\n",
        "\n",
        "# setting the legend for the plot\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "# adding the grid\n",
        "plt.grid()\n",
        "\n",
        "# showing the figure\n",
        "plt.show(loss_lc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the VGG19"
      ],
      "metadata": {
        "id": "w9akggxZMnZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on the entire test set\n",
        "In this section the test phase is carried out for the net that has just been trained.\n"
      ],
      "metadata": {
        "id": "vGTasCh5r0n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_history = model.evaluate(X_test,y_test,batch_size = 8)\n",
        "print(\"Test Loss : %f , Test Accuracy : %f\" %(test_history[0],test_history[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjDFmw0Tr7IG",
        "outputId": "95585490-4784-4228-e1d1-241c76722a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "449/449 [==============================] - 15s 31ms/step - loss: 1.3747 - accuracy: 0.5500\n",
            "Test Loss : 1.374674 , Test Accuracy : 0.550014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the confusion matrix\n"
      ],
      "metadata": {
        "id": "sD6QVKGVMpBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the predictions on the test set\n",
        "y_pred=model.predict(X_test,verbose=0) \n",
        "\n",
        "# creating the confusion matrix and the confusion matrix display\n",
        "cm = confusion_matrix( y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "cm_display = ConfusionMatrixDisplay(cm,display_labels=[\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"])\n",
        "\n",
        "# creating the figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "# plotting the confusion matrix\n",
        "cm_display = cm_display.plot(ax=ax)"
      ],
      "metadata": {
        "id": "dQN2mK2KKTqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1yzikI-EfrW"
      },
      "source": [
        "## Computing classification report and class accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the classification report\n",
        "print(\"Classification report: \\n\")\n",
        "emotions = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"]\n",
        "print(classification_report(y_test.argmax(1),y_pred.argmax(1),labels = [0,1,2,3,4,5,6],target_names = emotions))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Computing and visualizing class accuracy\n",
        "\n",
        "print(\"Class accuracy: \\n\")\n",
        "cl_acc = []\n",
        "tp_p_tn = cm.diagonal().sum()\n",
        "for i in range(7):\n",
        "  fp = cm[:,i].sum()\n",
        "  fn = cm[i].sum()\n",
        "  acc = tp_p_tn / (tp_p_tn+fp+fn-2*cm[i][i])\n",
        "  cl_acc.append(acc)\n",
        "\n",
        "for i in range(7):\n",
        "  print(\"%s : %f\\n\"%(emotions[i],cl_acc[i]))\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "oL0NFELqKax9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tac-aVro4Krd"
      },
      "source": [
        "## Saving the model\n",
        "After training and testing the model we save it for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZBVZt7o4Wts"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Facial-Expression-Recognition/VGG19.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2M7cmWk94Q9"
      },
      "source": [
        "## Visualizing model performances\n",
        "In this section the trained model will be loaded and then its performances will be displayed.\\\n",
        "More specifically:\n",
        "\n",
        "\n",
        "*   A random batch of images will be extracted from the Test Set.\n",
        "*   The extracted images will be displayed with their real labels (groundtruth)\n",
        "* The extracted images will be displayed with the labels predicted by the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF5X_te3FzNn"
      },
      "outputs": [],
      "source": [
        "# Loading the model\n",
        "model = load_model(\"/content/drive/MyDrive/Facial-Expression-Recognition/VGG19.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qtpJ8aDABy2"
      },
      "outputs": [],
      "source": [
        "# Getting the number of random images to extract from the user\n",
        "n = int(input(\"Enter the number of random images to extract: \"))\n",
        "\n",
        "# Generating the random images batch\n",
        "images,labels = random_images(X_test,y_test,n)\n",
        "\n",
        "# Visualizing the images with their real labels\n",
        "print(\"Groundtruth:\\n\")\n",
        "print_images_with_labels(images,labels)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Visualizing the images with the predicted labels\n",
        "pred = convert_to_tensor(model(images))\n",
        "print(\"Model predictions:\\n\")\n",
        "print_images_with_labels(images,pred)"
      ]
    }
  ]
}